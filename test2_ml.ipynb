{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at bytesizedllm/MalayalamXLM_Roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/rohit/anaconda3/envs/xlstm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/rohit/anaconda3/envs/xlstm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:32<00:00,  1.24it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.66it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:06<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro F1-Score: 0.8598\n",
      "Classification Report on Test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       122\n",
      "           1       0.88      0.77      0.82        78\n",
      "\n",
      "    accuracy                           0.87       200\n",
      "   macro avg       0.87      0.85      0.86       200\n",
      "weighted avg       0.87      0.87      0.87       200\n",
      "\n",
      "Classification Report on Validation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88        97\n",
      "           1       0.88      0.71      0.79        63\n",
      "\n",
      "    accuracy                           0.85       160\n",
      "   macro avg       0.86      0.83      0.84       160\n",
      "weighted avg       0.85      0.85      0.85       160\n",
      "\n",
      "New best Macro F1-Score: 0.8598. Saving model...\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:27<00:00,  1.43it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.76it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:06<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro F1-Score: 0.8648\n",
      "Classification Report on Test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       122\n",
      "           1       0.90      0.77      0.83        78\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.86      0.86       200\n",
      "weighted avg       0.88      0.88      0.87       200\n",
      "\n",
      "Classification Report on Validation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91        97\n",
      "           1       0.92      0.78      0.84        63\n",
      "\n",
      "    accuracy                           0.89       160\n",
      "   macro avg       0.90      0.87      0.88       160\n",
      "weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "New best Macro F1-Score: 0.8648. Saving model...\n",
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:28<00:00,  1.39it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.82it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:05<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro F1-Score: 0.8805\n",
      "Classification Report on Test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       122\n",
      "           1       0.83      0.88      0.86        78\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.88      0.88      0.88       200\n",
      "weighted avg       0.89      0.89      0.89       200\n",
      "\n",
      "Classification Report on Validation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91        97\n",
      "           1       0.92      0.78      0.84        63\n",
      "\n",
      "    accuracy                           0.89       160\n",
      "   macro avg       0.90      0.87      0.88       160\n",
      "weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "New best Macro F1-Score: 0.8805. Saving model...\n",
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:27<00:00,  1.44it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.69it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:06<00:00,  1.86it/s]\n"
     ]
    }
    
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch.nn.functional as F\n",
    "from models improt MultimodalModel\n",
    "\n",
    "\n",
    "\n",
    "# Define the dataset class\n",
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, tokenizer, max_length, transform):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.data = self.data[self.data['image_id'].apply(lambda x: os.path.isfile(os.path.join(self.image_folder, f\"{x}.jpg\")))]\n",
    "\n",
    "        # Check if the image file exists for each row, raise an error if any file is missing\n",
    "        missing_files = self.data[~self.data['image_id'].apply(lambda x: os.path.isfile(os.path.join(self.image_folder, f\"{x}.jpg\")))]\n",
    "\n",
    "        if not missing_files.empty:\n",
    "            raise FileNotFoundError(f\"The following image files are missing: {', '.join(missing_files['image_id'].tolist())}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_id = row['image_id']\n",
    "        label = row['labels']\n",
    "        transcription = row['transcriptions'].lower()\n",
    "        \n",
    "        # Tokenize text\n",
    "        text_inputs = self.tokenizer(\n",
    "            transcription,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Load and transform image\n",
    "        image_path = os.path.join(self.image_folder, f\"{image_id}.jpg\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return {\n",
    "            'text_inputs': {key: val.squeeze(0) for key, val in text_inputs.items()},\n",
    "            'image': image,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training and evaluation setup\n",
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, leave=True, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        text_inputs = {key: val.to(device) for key, val in batch['text_inputs'].items()}\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        loss, outputs = model(text_inputs, images, labels=labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, leave=True, desc=\"Evaluating\"):\n",
    "            text_inputs = {key: val.to(device) for key, val in batch['text_inputs'].items()}\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            loss, outputs = model(text_inputs, images, labels=labels)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    return total_loss / len(dataloader), predictions, true_labels\n",
    "\n",
    "\n",
    "\n",
    "image_folder = \"./malayalam/all\"  # Path to the folder containing images\n",
    "text_model_name = \"bytesizedllm/MalayalamXLM_Roberta\"\n",
    "num_classes = 2\n",
    "max_length = 64\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Tokenizer and transformations\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_model_name, cache_dir=\"./xlm_robertaMalayalam\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = MemeDataset(\"./malayalam/all/train.csv\", image_folder, tokenizer, max_length, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = MemeDataset(\"./malayalam/all/dev.csv\", image_folder, tokenizer, max_length, transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = MemeDataset(\"./malayalam/test_with_labels/test_with_labels.csv\", image_folder, tokenizer, max_length, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "model = MultimodalModel(text_model_name, num_classes).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2.5e-5, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# # Main Training Loop\n",
    "best_macro_f1 = 0.0\n",
    "best_model_path = \"./malayalam/best_modelM.pth\"\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_predictions, val_true_labels = evaluate_model(model, val_loader, criterion, device)\n",
    "    test_loss, test_predictions, test_true_labels = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "    report = classification_report(test_true_labels, test_predictions)\n",
    "    report1 = classification_report(test_true_labels, test_predictions, output_dict=True)\n",
    "    macro_f1 = report1['macro avg']['f1-score']\n",
    "    \n",
    "\n",
    "\n",
    "    # Save best model\n",
    "    if macro_f1 > best_macro_f1:\n",
    "        best_macro_f1 = macro_f1\n",
    "        print(f\"Test Macro F1-Score: {macro_f1:.4f}\")\n",
    "        print(\"Classification Report on Test:\\n\", report)\n",
    "        print(\"Classification Report on Validation:\\n\", classification_report(val_true_labels, val_predictions))\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best Macro F1-Score: {best_macro_f1:.4f}. Saving model...\")\n",
    "\n",
    "print(f\"Best Macro F1-Score achieved on Test set: {best_macro_f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab311e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a82c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xlstm] *",
   "language": "python",
   "name": "conda-env-xlstm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
